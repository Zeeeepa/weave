"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[9926],{19016:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>p,frontMatter:()=>r,metadata:()=>a,toc:()=>d});var i=t(85893),o=t(11151);const r={title:"Handling and Redacting PII"},s="How to use Weave with PII data:",a={id:"reference/gen_notebooks/pii",title:"Handling and Redacting PII",description:"Open in Colab",source:"@site/docs/reference/gen_notebooks/pii.md",sourceDirName:"reference/gen_notebooks",slug:"/reference/gen_notebooks/pii",permalink:"/reference/gen_notebooks/pii",draft:!1,unlisted:!1,editUrl:"https://github.com/wandb/weave/blob/master/docs/docs/reference/gen_notebooks/pii.md",tags:[],version:"current",lastUpdatedAt:1735687006e3,frontMatter:{title:"Handling and Redacting PII"},sidebar:"notebookSidebar",previous:{title:"online_monitoring",permalink:"/reference/gen_notebooks/online_monitoring"},next:{title:"weave_via_service_api",permalink:"/reference/gen_notebooks/weave_via_service_api"}},l={},d=[{value:"Overview of Weave Ops Input/Output Logging Customization",id:"overview-of-weave-ops-inputoutput-logging-customization",level:2},{value:"Method 1: Regular Expression Filtering",id:"method-1-regular-expression-filtering",level:2},{value:"Method 2: Microsoft Presidio Redaction",id:"method-2-microsoft-presidio-redaction",level:2},{value:"Method 3: Anonymization with Replacement using Fakr and Presidio",id:"method-3-anonymization-with-replacement-using-fakr-and-presidio",level:2},{value:"Regex Method",id:"regex-method",level:2},{value:"Presidio Redaction Method",id:"presidio-redaction-method",level:2},{value:"Faker + Presidio Replacement Method",id:"faker--presidio-replacement-method",level:2},{value:"Checklist for Safely Using Weave with PII Data",id:"checklist-for-safely-using-weave-with-pii-data",level:2},{value:"During Testing",id:"during-testing",level:3},{value:"In Production",id:"in-production",level:3},{value:"Encryption Tips",id:"encryption-tips",level:3}];function c(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.a)(),...e.components},{Details:r}=n;return r||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(n.admonition,{title:"This is a notebook",type:"tip",children:[(0,i.jsx)("a",{href:"https://colab.research.google.com/github/wandb/weave/blob/master/docs/./notebooks/pii.ipynb",target:"_blank",rel:"noopener noreferrer",class:"navbar__item navbar__link button button--secondary button--med margin-right--sm notebook-cta-button",children:(0,i.jsxs)("div",{children:[(0,i.jsx)("img",{src:"https://upload.wikimedia.org/wikipedia/commons/archive/d/d0/20221103151430%21Google_Colaboratory_SVG_Logo.svg",alt:"Open In Colab",height:"20px"}),(0,i.jsx)("div",{children:"Open in Colab"})]})}),(0,i.jsx)("a",{href:"https://github.com/wandb/weave/blob/master/docs/./notebooks/pii.ipynb",target:"_blank",rel:"noopener noreferrer",class:"navbar__item navbar__link button button--secondary button--med margin-right--sm notebook-cta-button",children:(0,i.jsxs)("div",{children:[(0,i.jsx)("img",{src:"https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg",alt:"View in Github",height:"15px"}),(0,i.jsx)("div",{children:"View in Github"})]})})]}),"\n",(0,i.jsx)(n.h1,{id:"how-to-use-weave-with-pii-data",children:"How to use Weave with PII data:"}),"\n",(0,i.jsx)(n.p,{children:"In this tutorial, we'll demonstrate how to utilize Weave while ensuring your Personally Identifiable Information (PII) data remains private. Weave supports removing PII from LLM calls and preventing PII from being displayed in the Weave UI."}),"\n",(0,i.jsx)(n.p,{children:"To detect and protect our PII data, we'll identify and redact PII data and optionally anonymize it with the following methods:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Regular expressions"})," to identify PII data and redact it."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:["Microsoft's ",(0,i.jsx)(n.a,{href:"https://microsoft.github.io/presidio/",children:"Presidio"})]}),", a python-based data protection SDK. This tool provides redaction and replacement functionalities."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"https://faker.readthedocs.io/en/master/",children:"Faker"})}),", a Python library to generate fake data, combined with Presidio to anonymize PII data."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Additionally, we'll make use of ",(0,i.jsx)(n.em,{children:"Weave Ops input/output logging customization"})," to seamlessly integrate PII redaction and anonymization into the workflow. See ",(0,i.jsx)(n.a,{href:"https://weave-docs.wandb.ai/guides/tracking/ops/#customize-logged-inputs-and-outputs",children:"here"})," for more information."]}),"\n",(0,i.jsxs)(n.p,{children:["For this use-case, we will leverage Anthropic's Claude Sonnet to perform sentiment analysis while tracing the LLM calls using Weave's ",(0,i.jsx)(n.a,{href:"https://wandb.github.io/weave/quickstart",children:"Traces"}),". Sonnet will receive a block of text and output one of the following sentiment classifications: ",(0,i.jsx)(n.em,{children:"positive"}),", ",(0,i.jsx)(n.em,{children:"negative"}),", or ",(0,i.jsx)(n.em,{children:"neutral"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"overview-of-weave-ops-inputoutput-logging-customization",children:"Overview of Weave Ops Input/Output Logging Customization"}),"\n",(0,i.jsx)(n.p,{children:"Weave Ops support defining input and output postprocessing functions. These functions allow you to modify the data that is passed to your LLM call or logged to Weave, respectively."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from dataclasses import dataclass\nfrom typing import Any\n\nimport weave\n\n# Inputs Wrapper Class\n@dataclass\nclass CustomObject:\n    x: int\n    secret_password: str\n\n# First we define functions for input and output postprocessing:\ndef postprocess_inputs(inputs: dict[str, Any]) -> dict[str, Any]:\n    return {k:v for k,v in inputs.items() if k != "hide_me"}\n\ndef postprocess_output(output: CustomObject) -> CustomObject:\n    return CustomObject(x=output.x, secret_password="REDACTED")\n\n# Then, when we use the `@weave.op` decorator, we pass these processing functions as arguments to the decorator:\n@weave.op(\n    postprocess_inputs=postprocess_inputs,\n    postprocess_output=postprocess_output,\n)\ndef some_llm_call(a: int, hide_me: str) -> CustomObject:\n    return CustomObject(x=a, secret_password=hide_me)\n'})}),"\n",(0,i.jsx)(n.h1,{id:"setup",children:"Setup"}),"\n",(0,i.jsxs)(n.p,{children:["Let's install the required packages and set up our API keys. Your Weights & Biases API key can be found ",(0,i.jsx)(n.a,{href:"https://wandb.ai/authorize",children:"here"}),", and your Anthropic API keys are ",(0,i.jsx)(n.a,{href:"https://console.anthropic.com/settings/keys",children:"here"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"%%capture\n# @title required python packages:\n!pip install presidio_analyzer\n!pip install presidio_anonymizer\n!python -m spacy download en_core_web_lg    # Presidio uses spacy NLP engine\n!pip install Faker                          # we'll use Faker to replace PII data with fake data\n!pip install weave                          # To leverage Traces\n!pip install set-env-colab-kaggle-dotenv -q # for env var\n!pip install anthropic                      # to use sonnet\n!pip install cryptography                   # to encrypt our data\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'%%capture\n# @title Make sure to set up set up your API keys correctly\n# See: https://pypi.org/project/set-env-colab-kaggle-dotenv/ for usage instructions.\n\nfrom set_env import set_env\n\n_ = set_env("ANTHROPIC_API_KEY")\n_ = set_env("WANDB_API_KEY")\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import weave\n\n# Start a new Weave project\nWEAVE_PROJECT = "pii_cookbook"\nweave.init(WEAVE_PROJECT)\n'})}),"\n",(0,i.jsx)(n.p,{children:"Let's load our initial PII data. For demonstration purposes, we'll use a dataset containing 10 text blocks. A larger dataset with 1000 entries is available."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import requests\n\nurl = "https://raw.githubusercontent.com/wandb/weave/master/docs/notebooks/10_pii_data.json"\nresponse = requests.get(url)\npii_data = response.json()\n\nprint(\'PII data first sample: "\' + pii_data[0]["text"] + \'"\')\n'})}),"\n",(0,i.jsx)(n.h1,{id:"redaction-methods-implementation",children:"Redaction Methods Implementation"}),"\n",(0,i.jsx)(n.h2,{id:"method-1-regular-expression-filtering",children:"Method 1: Regular Expression Filtering"}),"\n",(0,i.jsxs)(n.p,{children:["Our initial method is to use ",(0,i.jsx)(n.a,{href:"https://docs.python.org/3/library/re.html",children:"regular expressions (regex)"})," to identify PII data and redact it. It allows us to define patterns that can match various formats of sensitive information like phone numbers, email addresses, and social security numbers. By using regex, we can scan through large volumes of text and replace or redact information without the need for more complex NLP techniques."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import re\n\n\n# Define a function to clean PII data using regex\ndef redact_with_regex(text):\n    # Phone number pattern\n    # \\b         : Word boundary\n    # \\d{3}      : Exactly 3 digits\n    # [-.]?      : Optional hyphen or dot\n    # \\d{3}      : Another 3 digits\n    # [-.]?      : Optional hyphen or dot\n    # \\d{4}      : Exactly 4 digits\n    # \\b         : Word boundary\n    text = re.sub(r"\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b", "<PHONE>", text)\n\n    # Email pattern\n    # \\b         : Word boundary\n    # [A-Za-z0-9._%+-]+ : One or more characters that can be in an email username\n    # @          : Literal @ symbol\n    # [A-Za-z0-9.-]+ : One or more characters that can be in a domain name\n    # \\.         : Literal dot\n    # [A-Z|a-z]{2,} : Two or more uppercase or lowercase letters (TLD)\n    # \\b         : Word boundary\n    text = re.sub(\n        r"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b", "<EMAIL>", text\n    )\n\n    # SSN pattern\n    # \\b         : Word boundary\n    # \\d{3}      : Exactly 3 digits\n    # -          : Literal hyphen\n    # \\d{2}      : Exactly 2 digits\n    # -          : Literal hyphen\n    # \\d{4}      : Exactly 4 digits\n    # \\b         : Word boundary\n    text = re.sub(r"\\b\\d{3}-\\d{2}-\\d{4}\\b", "<SSN>", text)\n\n    # Simple name pattern (this is not comprehensive)\n    # \\b         : Word boundary\n    # [A-Z]      : One uppercase letter\n    # [a-z]+     : One or more lowercase letters\n    # \\s         : One whitespace character\n    # [A-Z]      : One uppercase letter\n    # [a-z]+     : One or more lowercase letters\n    # \\b         : Word boundary\n    text = re.sub(r"\\b[A-Z][a-z]+ [A-Z][a-z]+\\b", "<NAME>", text)\n\n    return text\n'})}),"\n",(0,i.jsx)(n.p,{children:"Let's test the function with a sample text:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Test the function\ntest_text = "My name is John Doe, my email is john.doe@example.com, my phone is 123-456-7890, and my SSN is 123-45-6789."\ncleaned_text = redact_with_regex(test_text)\nprint(f"Raw text:\\n\\t{test_text}")\nprint(f"Redacted text:\\n\\t{cleaned_text}")\n'})}),"\n",(0,i.jsx)(n.h2,{id:"method-2-microsoft-presidio-redaction",children:"Method 2: Microsoft Presidio Redaction"}),"\n",(0,i.jsx)(n.p,{children:"Our next method involves complete removal of PII data using Presidio. This approach redacts PII and replaces it with a placeholder representing the PII type."}),"\n",(0,i.jsxs)(n.p,{children:["For example:\n",(0,i.jsx)(n.code,{children:'"My name is Alex"'})," becomes ",(0,i.jsx)(n.code,{children:'"My name is <PERSON>"'}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["Presidio comes with a built-in ",(0,i.jsx)(n.a,{href:"https://microsoft.github.io/presidio/supported_entities/",children:"list of recognizable entities"}),". We can select the ones that are important for our use case. In the below example, we redact names, phone numbers, locations, email addresses, and US Social Security Numbers."]}),"\n",(0,i.jsx)(n.p,{children:"We'll then encapsulate the Presidio process into a function."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from presidio_analyzer import AnalyzerEngine\nfrom presidio_anonymizer import AnonymizerEngine\n\n# Set up the Analyzer, which loads an NLP module (spaCy model by default) and other PII recognizers.\nanalyzer = AnalyzerEngine()\n\n# Set up the Anonymizer, which will use the analyzer results to anonymize the text.\nanonymizer = AnonymizerEngine()\n\n\n# Encapsulate the Presidio redaction process into a function\ndef redact_with_presidio(text):\n    # Analyze the text to identify PII data\n    results = analyzer.analyze(\n        text=text,\n        entities=["PHONE_NUMBER", "PERSON", "LOCATION", "EMAIL_ADDRESS", "US_SSN"],\n        language="en",\n    )\n    # Anonymize the identified PII data\n    anonymized_text = anonymizer.anonymize(text=text, analyzer_results=results)\n    return anonymized_text.text\n'})}),"\n",(0,i.jsx)(n.p,{children:"Let's test the function with a sample text:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'text = "My phone number is 212-555-5555 and my name is alex"\n\n# Test the function\nanonymized_text = redact_with_presidio(text)\n\nprint(f"Raw text:\\n\\t{text}")\nprint(f"Redacted text:\\n\\t{anonymized_text}")\n'})}),"\n",(0,i.jsx)(n.h2,{id:"method-3-anonymization-with-replacement-using-fakr-and-presidio",children:"Method 3: Anonymization with Replacement using Fakr and Presidio"}),"\n",(0,i.jsxs)(n.p,{children:["Instead of redacting text, we can anonymize it by swapping PII (like names and phone numbers) with fake data generated using the ",(0,i.jsx)(n.a,{href:"https://faker.readthedocs.io/en/master/",children:"Faker"})," Python library. For example:"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:'"My name is Raphael and I like to fish. My phone number is 212-555-5555"'})}),"\n",(0,i.jsx)(n.p,{children:"might become"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:'"My name is Katherine Dixon and I like to fish. My phone number is 667.431.7379"'})}),"\n",(0,i.jsx)(n.p,{children:"To effectively utilize Presidio, we must supply references to our custom operators. These operators will direct Presidio to the functions responsible for swapping PII with fake data."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from faker import Faker\nfrom presidio_anonymizer import AnonymizerEngine\nfrom presidio_anonymizer.entities import OperatorConfig\n\nfake = Faker()\n\n\n# Create faker functions (note that it has to receive a value)\ndef fake_name(x):\n    return fake.name()\n\n\ndef fake_number(x):\n    return fake.phone_number()\n\n\n# Create custom operator for the PERSON and PHONE_NUMBER" entities\noperators = {\n    "PERSON": OperatorConfig("custom", {"lambda": fake_name}),\n    "PHONE_NUMBER": OperatorConfig("custom", {"lambda": fake_number}),\n}\n\ntext_to_anonymize = (\n    "My name is Raphael and I like to fish. My phone number is 212-555-5555"\n)\n\n# Analyzer output\nanalyzer_results = analyzer.analyze(\n    text=text_to_anonymize, entities=["PHONE_NUMBER", "PERSON"], language="en"\n)\n\nanonymizer = AnonymizerEngine()\n\n# do not forget to pass the operators from above to the anonymizer\nanonymized_results = anonymizer.anonymize(\n    text=text_to_anonymize, analyzer_results=analyzer_results, operators=operators\n)\n\nprint(f"Raw text:\\n\\t{text_to_anonymize}")\nprint(f"Anonymized text:\\n\\t{anonymized_results.text}")\n'})}),"\n",(0,i.jsx)(n.p,{children:"Let's consolidate our code into a single class and expand the list of entities to include the additional ones we identified earlier."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from faker import Faker\nfrom presidio_anonymizer import AnonymizerEngine\nfrom presidio_anonymizer.entities import OperatorConfig\n\n\n# A custom class for generating fake data that extends Faker\nclass my_faker(Faker):\n    # Create faker functions (note that it has to receive a value)\n    def fake_address(x):\n        return fake.address()\n\n    def fake_ssn(x):\n        return fake.ssn()\n\n    def fake_name(x):\n        return fake.name()\n\n    def fake_number(x):\n        return fake.phone_number()\n\n    def fake_email(x):\n        return fake.email()\n\n    # Create custom operators for the entities\n    operators = {\n        "PERSON": OperatorConfig("custom", {"lambda": fake_name}),\n        "PHONE_NUMBER": OperatorConfig("custom", {"lambda": fake_number}),\n        "EMAIL_ADDRESS": OperatorConfig("custom", {"lambda": fake_email}),\n        "LOCATION": OperatorConfig("custom", {"lambda": fake_address}),\n        "US_SSN": OperatorConfig("custom", {"lambda": fake_ssn}),\n    }\n\n    def redact_and_anonymize_with_faker(self, text):\n        anonymizer = AnonymizerEngine()\n        analyzer_results = analyzer.analyze(\n            text=text,\n            entities=["PHONE_NUMBER", "PERSON", "LOCATION", "EMAIL_ADDRESS", "US_SSN"],\n            language="en",\n        )\n        anonymized_results = anonymizer.anonymize(\n            text=text, analyzer_results=analyzer_results, operators=self.operators\n        )\n        return anonymized_results.text\n'})}),"\n",(0,i.jsx)(n.p,{children:"Let's test the function with a sample text:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'faker = my_faker()\ntext_to_anonymize = (\n    "My name is Raphael and I like to fish. My phone number is 212-555-5555"\n)\nanonymized_text = faker.redact_and_anonymize_with_faker(text_to_anonymize)\n\nprint(f"Raw text:\\n\\t{text_to_anonymize}")\nprint(f"Anonymized text:\\n\\t{anonymized_text}")\n'})}),"\n",(0,i.jsx)(n.h1,{id:"applying-the-methods-to-weave-calls",children:"Applying the Methods to Weave Calls"}),"\n",(0,i.jsx)(n.p,{children:"In these examples we will integrate our PII redaction and anonymization methods into Weave Models, and preview the results in Weave Traces."}),"\n",(0,i.jsxs)(n.p,{children:["We'll create a ",(0,i.jsx)(n.a,{href:"https://wandb.github.io/weave/guides/core-types/models",children:"Weave Model"})," which is a combination of data (which can include configuration, trained model weights, or other information) and code that defines how the model operates."]}),"\n",(0,i.jsx)(n.p,{children:"In this model, we will include our predict function where the Anthropic API will be called. Additionally, we will include our postprocessing functions to ensure that our PII data is redacted or anonymized before it is sent to the LLM."}),"\n",(0,i.jsx)(n.p,{children:"Once you run this code you will receive a links to the Weave project page as well as the specific trace (LLM calls)you ran."}),"\n",(0,i.jsx)(n.h2,{id:"regex-method",children:"Regex Method"}),"\n",(0,i.jsx)(n.p,{children:"In the simplest case, we can use regex to identify and redact PII data in the original text."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import json\nfrom typing import Any\n\nimport anthropic\n\nimport weave\n\n\n# Define an input postprocessing function that applies our regex redaction for the model prediction Weave Op\ndef postprocess_inputs_regex(inputs: dict[str, Any]) -> dict:\n    inputs["text_block"] = redact_with_regex(inputs["text_block"])\n    return inputs\n\n\n# Weave model / predict function\nclass sentiment_analysis_regex_pii_model(weave.Model):\n    model_name: str\n    system_prompt: str\n    temperature: int\n\n    @weave.op(\n        postprocess_inputs=postprocess_inputs_regex,\n    )\n    async def predict(self, text_block: str) -> dict:\n        client = anthropic.AsyncAnthropic()\n        response = await client.messages.create(\n            max_tokens=1024,\n            model=self.model_name,\n            system=self.system_prompt,\n            messages=[\n                {"role": "user", "content": [{"type": "text", "text": text_block}]}\n            ],\n        )\n        result = response.content[0].text\n        if result is None:\n            raise ValueError("No response from model")\n        parsed = json.loads(result)\n        return parsed\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# create our LLM model with a system prompt\nmodel = sentiment_analysis_regex_pii_model(\n    name="claude-3-sonnet",\n    model_name="claude-3-5-sonnet-20240620",\n    system_prompt=\'You are a Sentiment Analysis classifier. You will be classifying text based on their sentiment. Your input will be a block of text. You will answer with one the following rating option["positive", "negative", "neutral"]. Your answer should be one word in json format: {classification}. Ensure that it is valid JSON.\',\n    temperature=0,\n)\n\nprint("Model: ", model)\n# for every block of text, anonymized first and then predict\nfor entry in pii_data:\n    await model.predict(entry["text"])\n'})}),"\n",(0,i.jsx)(n.h2,{id:"presidio-redaction-method",children:"Presidio Redaction Method"}),"\n",(0,i.jsx)(n.p,{children:"Here we will use Presidio to identify and redact PII data in the original text."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(37065).Z+"",width:"3024",height:"1890"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import json\nfrom typing import Any\n\nimport anthropic\n\nimport weave\n\n\n# Define an input postprocessing function that applies our Presidio redaction for the model prediction Weave Op\ndef postprocess_inputs_presidio(inputs: dict[str, Any]) -> dict:\n    inputs["text_block"] = redact_with_presidio(inputs["text_block"])\n    return inputs\n\n\n# Weave model / predict function\nclass sentiment_analysis_presidio_pii_model(weave.Model):\n    model_name: str\n    system_prompt: str\n    temperature: int\n\n    @weave.op(\n        postprocess_inputs=postprocess_inputs_presidio,\n    )\n    async def predict(self, text_block: str) -> dict:\n        client = anthropic.AsyncAnthropic()\n        response = await client.messages.create(\n            max_tokens=1024,\n            model=self.model_name,\n            system=self.system_prompt,\n            messages=[\n                {"role": "user", "content": [{"type": "text", "text": text_block}]}\n            ],\n        )\n        result = response.content[0].text\n        if result is None:\n            raise ValueError("No response from model")\n        parsed = json.loads(result)\n        return parsed\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# create our LLM model with a system prompt\nmodel = sentiment_analysis_presidio_pii_model(\n    name="claude-3-sonnet",\n    model_name="claude-3-5-sonnet-20240620",\n    system_prompt=\'You are a Sentiment Analysis classifier. You will be classifying text based on their sentiment. Your input will be a block of text. You will answer with one the following rating option["positive", "negative", "neutral"]. Your answer should be one word in json format: {classification}. Ensure that it is valid JSON.\',\n    temperature=0,\n)\n\nprint("Model: ", model)\n# for every block of text, anonymized first and then predict\nfor entry in pii_data:\n    await model.predict(entry["text"])\n'})}),"\n",(0,i.jsx)(n.h2,{id:"faker--presidio-replacement-method",children:"Faker + Presidio Replacement Method"}),"\n",(0,i.jsx)(n.p,{children:"Here we will have Faker generate anonymized replacement PII data and use Presidio to identify and replace the PII data in the original text."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(4627).Z+"",width:"3024",height:"1900"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import json\nfrom typing import Any\n\nimport anthropic\n\nimport weave\n\n# Define an input postprocessing function that applies our Faker anonymization and Presidio redaction for the model prediction Weave Op\nfaker = my_faker()\n\n\ndef postprocess_inputs_faker(inputs: dict[str, Any]) -> dict:\n    inputs["text_block"] = faker.redact_and_anonymize_with_faker(inputs["text_block"])\n    return inputs\n\n\n# Weave model / predict function\nclass sentiment_analysis_faker_pii_model(weave.Model):\n    model_name: str\n    system_prompt: str\n    temperature: int\n\n    @weave.op(\n        postprocess_inputs=postprocess_inputs_faker,\n    )\n    async def predict(self, text_block: str) -> dict:\n        client = anthropic.AsyncAnthropic()\n        response = await client.messages.create(\n            max_tokens=1024,\n            model=self.model_name,\n            system=self.system_prompt,\n            messages=[\n                {"role": "user", "content": [{"type": "text", "text": text_block}]}\n            ],\n        )\n        result = response.content[0].text\n        if result is None:\n            raise ValueError("No response from model")\n        parsed = json.loads(result)\n        return parsed\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# create our LLM model with a system prompt\nmodel = sentiment_analysis_faker_pii_model(\n    name="claude-3-sonnet",\n    model_name="claude-3-5-sonnet-20240620",\n    system_prompt=\'You are a Sentiment Analysis classifier. You will be classifying text based on their sentiment. Your input will be a block of text. You will answer with one the following rating option["positive", "negative", "neutral"]. Your answer should be one word in json format: {classification}. Ensure that it is valid JSON.\',\n    temperature=0,\n)\n\nprint("Model: ", model)\n# for every block of text, anonymized first and then predict\nfor entry in pii_data:\n    await model.predict(entry["text"])\n'})}),"\n",(0,i.jsx)(n.h2,{id:"checklist-for-safely-using-weave-with-pii-data",children:"Checklist for Safely Using Weave with PII Data"}),"\n",(0,i.jsx)(n.h3,{id:"during-testing",children:"During Testing"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Log anonymized data to check PII detection"}),"\n",(0,i.jsx)(n.li,{children:"Track PII handling processes with Weave Traces"}),"\n",(0,i.jsx)(n.li,{children:"Measure anonymization performance without exposing real PII"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"in-production",children:"In Production"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Never log raw PII"}),"\n",(0,i.jsx)(n.li,{children:"Encrypt sensitive fields before logging"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"encryption-tips",children:"Encryption Tips"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Use reversible encryption for data you need to decrypt later"}),"\n",(0,i.jsx)(n.li,{children:"Apply one-way hashing for unique IDs you don't need to reverse"}),"\n",(0,i.jsx)(n.li,{children:"Consider specialized encryption for data you need to analyze while encrypted"}),"\n"]}),"\n",(0,i.jsxs)(r,{children:[(0,i.jsxs)(n.p,{children:[(0,i.jsx)("summary",{children:" (Optional) Encrypting our data "}),"\n",(0,i.jsx)(n.img,{src:t(73484).Z+"",width:"3024",height:"1890"})]}),(0,i.jsxs)(n.p,{children:["In addition to anonymizing PII, we can add an extra layer of security by encrypting our data using the cryptography library's ",(0,i.jsx)(n.a,{href:"https://cryptography.io/en/latest/fernet/",children:"Fernet"})," symmetric encryption. This approach ensures that even if the anonymized data is intercepted, it remains unreadable without the encryption key."]}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import os\nfrom cryptography.fernet import Fernet\nfrom pydantic import BaseModel, ValidationInfo, model_validator\n\ndef get_fernet_key():\n    # Check if the key exists in environment variables\n    key = os.environ.get(\'FERNET_KEY\')\n    \n    if key is None:\n        # If the key doesn\'t exist, generate a new one\n        key = Fernet.generate_key()\n        # Save the key to an environment variable\n        os.environ[\'FERNET_KEY\'] = key.decode()\n    else:\n        # If the key exists, ensure it\'s in bytes\n        key = key.encode()\n    \n    return key\n\ncipher_suite = Fernet(get_fernet_key())\n\nclass EncryptedSentimentAnalysisInput(BaseModel):\n    encrypted_text: str = None\n\n    @model_validator(mode="before")\n    def encrypt_fields(cls, values):\n        if "text" in values and values["text"] is not None:\n            values["encrypted_text"] = cipher_suite.encrypt(values["text"].encode()).decode()\n            del values["text"]\n        return values\n\n    @property\n    def text(self):\n        if self.encrypted_text:\n            return cipher_suite.decrypt(self.encrypted_text.encode()).decode()\n        return None\n\n    @text.setter\n    def text(self, value):\n        self.encrypted_text = cipher_suite.encrypt(str(value).encode()).decode()\n\n    @classmethod\n    def encrypt(cls, text: str):\n        return cls(text=text)\n\n    def decrypt(self):\n        return self.text\n\n# Modified sentiment_analysis_model to use the new EncryptedSentimentAnalysisInput\nclass sentiment_analysis_model(weave.Model):\n    model_name: str\n    system_prompt: str\n    temperature: int\n\n    @weave.op()\n    async def predict(self, encrypted_input: EncryptedSentimentAnalysisInput) -> dict:\n        client = AsyncAnthropic()\n\n        decrypted_text = encrypted_input.decrypt() # We use the custom class to decrypt the text\n\n        response = await client.messages.create(\n            max_tokens=1024,\n            model=self.model_name,\n            system=self.system_prompt,\n            messages=[\n                {   "role": "user",\n                    "content":[\n                        {\n                            "type": "text",\n                            "text": decrypted_text\n                        }\n                    ]\n                }\n            ]\n        )\n        result = response.content[0].text\n        if result is None:\n            raise ValueError("No response from model")\n        parsed = json.loads(result)\n        return parsed\n\nmodel = sentiment_analysis_model(\n    name="claude-3-sonnet",\n    model_name="claude-3-5-sonnet-20240620",\n    system_prompt="You are a Sentiment Analysis classifier. You will be classifying text based on their sentiment. Your input will be a block of text. You will answer with one the following rating option[\\"positive\\", \\"negative\\", \\"neutral\\"]. Your answer should one word in json format dict where the key is classification.",\n    temperature=0\n)\n\nfor entry in pii_data:\n    encrypted_input = EncryptedSentimentAnalysisInput.encrypt(entry["text"])\n    await model.predict(encrypted_input)\n'})})]})]})}function p(e={}){const{wrapper:n}={...(0,o.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},73484:(e,n,t)=>{t.d(n,{Z:()=>i});const i=t.p+"assets/images/encrypt-e3247b783f10515a4f750482ee76ab3d.png"},37065:(e,n,t)=>{t.d(n,{Z:()=>i});const i=t.p+"assets/images/redact-5cef75e7d713e638b0d926cf40d603d0.png"},4627:(e,n,t)=>{t.d(n,{Z:()=>i});const i=t.p+"assets/images/replace-25a9450753b40e6cf39f0f4390873146.png"},11151:(e,n,t)=>{t.d(n,{Z:()=>a,a:()=>s});var i=t(67294);const o={},r=i.createContext(o);function s(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);